[file_path]

; prefix of saving dir
prefix = /home/zzp1/PycharmProjects/BGRU_MHA

; base dir that datasets are saved in
dataset_base_dir = ${prefix}/Data_Processing/Generated_Datasets

; base dir that results are saved in
result_saving_base_dir = ${prefix}/Comparative_Experiment_Results/New_Localization_Data_5flod

[dataset]

; sequence length
seq_len = 40

; num of input features
feature_num = 4

; batch size
batch_size = 128

; num of workers in dataloader
num_workers = 4

; evaluate every n steps
eval_every_n_steps = 17

[model]

; num of layer groups
groups_num = 2

; model hidden dim
hidden_size = 256

; hidden size of feed forward layer
inner_layers_size = 128

; head num of self-attention
head_num = 4

; q,k,v dim
attention_size = 64

; drop out rate
dropout_rate = 0.1


[training]

; max num of training epochs
epochs = 10000

; which device for training, cpu/cuda
device = cuda

; learning rate
lr = 0.001

; weight for reconstruction loss
reconstruction_loss_weight = 1

; weight for imputation loss
imputation_loss_weight = 1

; weight for consistency loss
consistency_loss_weight = 1

; patience of early stopping, -1 means not applied (current early stopping is based on total loss)
early_stop_patience = 30

; max_norm for gradient clipping, set 0 to disable
max_norm = 0

; strategy on model saving, all/best/none. If set as none, then do not save models (mode for hyper-parameter searching)
model_saving_strategy = best